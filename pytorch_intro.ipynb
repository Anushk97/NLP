{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFmLsCjpZfrf"
   },
   "source": [
    "# Pytorch Introduction\n",
    "\n",
    "## Table of Content\n",
    "1. Numpy\n",
    "2. RL Q-learning example\n",
    "3. Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTBnlzhUcxRz"
   },
   "source": [
    "# 1. Numpy\n",
    "\n",
    "Numpy is an optimized library for matrix and vector computation.\n",
    "\n",
    "More information can be found in https://numpy.org/doc/stable/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1681648705331,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "4aHyi2TvEIFH",
    "outputId": "3ba2b0aa-e3e7-4737-c421-d7384dc33a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [1 2 3]\n",
      "y: [[3 4 5]]\n",
      "z: [[6 7]\n",
      " [8 9]]\n",
      "The shape of x is:  (3,) x is a 1-d vector!\n",
      "The shape of y is:  (1, 3) y is a row vector!\n",
      "The shape of z is:  (2, 2) z is a matrix!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(2)  # fix the random seed for reproducibility\n",
    "\n",
    "x = np.array([1,2,3])       # create a numpy array from a list\n",
    "y = np.array([[3,4,5]])\n",
    "z = np.array([[6,7], [8,9]])\n",
    "\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "print(\"z:\", z)\n",
    "\n",
    "print(\"The shape of x is: \", x.shape, \"x is a 1-d vector!\")\n",
    "print(\"The shape of y is: \", y.shape, \"y is a row vector!\")\n",
    "print(\"The shape of z is: \", z.shape, \"z is a matrix!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YnAjgfVE0LH"
   },
   "source": [
    "## numpy array axis\n",
    "\n",
    "Some useful function: np.max, np.min, np.amax, np.sum, np.mean, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681648742342,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "7uRgEJUBE01A",
    "outputId": "2ba0122d-4649-494d-bdb1-2ab4f62cc1ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [5 4]\n",
      " [3 6]]\n",
      "dd [2 5 6]\n",
      "[[2]\n",
      " [5]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2], [5,4], [3,6]])\n",
    "print(x)\n",
    "print('dd',np.max(x, axis=1))\n",
    "print(np.max(x, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1681648770775,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "EvRqzNjUE9QH",
    "outputId": "4f0d3c2b-1303-4bb7-beab-9c30a8721ab8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4359949 , 0.02592623, 0.54966248, 0.43532239],\n",
       "       [0.4203678 , 0.33033482, 0.20464863, 0.61927097],\n",
       "       [0.29965467, 0.26682728, 0.62113383, 0.52914209]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random( (3,4) )       # randomly initialize a (3,4) matrix\n",
    "x[:]                                # select everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SdOryFWE5FH"
   },
   "source": [
    "## Numpy indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1681648838943,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "qJW-8kRtE51X",
    "outputId": "3ac15128-cce8-48d5-a5c8-c4ede9a1f3e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4203678 , 0.33033482, 0.20464863, 0.61927097],\n",
       "       [0.29965467, 0.26682728, 0.62113383, 0.52914209]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[np.array([1, 2]), :]              # select the 0th and 2nd rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1681648852998,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "-oS7yVNUFRQw",
    "outputId": "57ea4a77-cce6-46f1-be09-9b1a034f946c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33033482, 0.20464863])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1, 1:3]                           # select 1st row as 1-D vector, and then the 1st through 2nd elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1681648868585,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "hJWvBguEFVLX",
    "outputId": "1b352f72-46d3-46f3-e644-d361b79ce93a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4359949 , 0.02592623, 0.43532239, 0.4203678 , 0.33033482,\n",
       "       0.20464863, 0.29965467, 0.26682728])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[x<0.5]                            # boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1681649445643,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "WS7u8S8NFYBX",
    "outputId": "65ef8257-f478-49bc-e7eb-71e916781cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s (3,)\n",
      "sh (3, 1)\n",
      "[[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1,2,3])\n",
    "print('s',y.shape)\n",
    "y2 = y[:, np.newaxis]                 # convert to 3-d vector of shape (3, 4, 1)\n",
    "print('sh',y2.shape)\n",
    "print(y2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7CFRc5UIItn"
   },
   "source": [
    "## numpy operation and broadcasting\n",
    "\n",
    "matrix operation: np.dot, np.matmul, .T, ......\n",
    "\n",
    "element-wise operator: +, -, *, **, /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1681649614088,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "fo_nVsI2IH2v",
    "outputId": "0d94a07a-0092-4831-d099-8783898cb958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [[0.226012   0.10694568]\n",
      " [0.22030621 0.34982629]\n",
      " [0.46778748 0.20174323]]\n",
      "B: [[0.64040673]\n",
      " [0.48306984]]\n"
     ]
    }
   ],
   "source": [
    "A = np.random.random( (3,2) )\n",
    "B = np.random.random( (2,1) )\n",
    "print(\"A:\", A)\n",
    "print(\"B:\", B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 513,
     "status": "ok",
     "timestamp": 1681649630646,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "rtW8REheIPQC",
    "outputId": "ba7d3e50-c1f5-4efd-b708-bdd905602fc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19640184],\n",
       "       [0.3100761 ],\n",
       "       [0.39703032]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.dot(A, B)                 # matrix product, also can use np.matmul, (3, 2) * (2, 1) leads to (3, 1)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1681649658177,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "QVCKexYMIWAK",
    "outputId": "26b11a8e-94e5-456e-e4ab-03902d89ab2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.226012  , 0.22030621, 0.46778748],\n",
       "       [0.10694568, 0.34982629, 0.20174323]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T                               # matrix transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AChfYHNAIZ5S"
   },
   "source": [
    "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when:\n",
    "\n",
    "1. they are equal, or\n",
    "2. one of them is 1 (in which case, elements on the axis are repeated along the dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681649699073,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "CQgOwRR5IYho",
    "outputId": "c64bf2b7-f9f8-486d-b81b-6f47fea664c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86641873, 0.86071293, 1.10819421],\n",
       "       [0.59001552, 0.83289612, 0.68481306]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = A.T                           # D: (2,3), B: (2,1)\n",
    "B+D                               # Broadcasting: adds B to each column of D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681649740790,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "Mq1Hq_l1IqQU",
    "outputId": "ad05b257-93ab-4c00-ca0a-1ad0179f68fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14473961, 0.05166223],\n",
       "       [0.14108558, 0.16899053],\n",
       "       [0.29957425, 0.09745607]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = B.T                           # E: (1, 2), A: (3,2)\n",
    "A*E                               # Broadcasting: multiples E (element-wise) with each row of A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkwyLJIHbZYo"
   },
   "source": [
    "\n",
    "# Reinforcement Learning Q-learning Example\n",
    "\n",
    "Please refer to the class slides for more details of Q-learning.\n",
    "\n",
    "Here is a simple example, the same with our class, from [MorvanZhou](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/1_command_line_reinforcement_learning/treasure_on_right.py) for Reinforcement Learning using table lookup Q-learning method.\n",
    "\n",
    "The environment is a 1 dimensional world that has 0, 1, 2, ..., n states. There is a treasure on the rightmost location n, which can give a reward +1! And other states offer 0 reward. \n",
    "\n",
    "An agent \"o\" is on the leftmost location 0. It has only two actions: [left, right].\n",
    "\n",
    "The goal of the agent is to explore the world and learn a Q-table to guide the agent for the treasure asap!\n",
    "\n",
    "Here is how we visualize the game:\n",
    "\n",
    "\n",
    "```\n",
    "-o---T\n",
    "# o is the position of agent (state 1), and T is the treature (state 5).\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDucF-EwKwYO"
   },
   "source": [
    "### Pre-defined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9X8OLoniKqcX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "np.random.seed(2)  # reproducible\n",
    "\n",
    "N_STATES = 6   # the length of the 1 dimensional world\n",
    "ACTIONS = ['left', 'right']     # available actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hSF2DG9ODZd"
   },
   "source": [
    "### Q-table\n",
    "First, we need to build a table to store the state-action value! A higher value usually denotes a high probability to take the action if the agent is at the state.\n",
    "\n",
    "An initial Q-table may be:\n",
    "\n",
    "| state\\action | left | right |\n",
    "|--------------|:----:|------:|\n",
    "| 0            |  0   |  0    |\n",
    "| 1            |  0   |  0    |\n",
    "| 2            |  0   |  0    |\n",
    "| 3            |  0   |  0    |\n",
    "| 4            |  0   |  0    |\n",
    "| 5            |  0   |  0    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681653385629,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "-904fl-9PPq1",
    "outputId": "1bed1e72-f46e-4161-a7b3-59af512f7be1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   left  right\n",
      "0   0.0    0.0\n",
      "1   0.0    0.0\n",
      "2   0.0    0.0\n",
      "3   0.0    0.0\n",
      "4   0.0    0.0\n",
      "5   0.0    0.0\n"
     ]
    }
   ],
   "source": [
    "def build_q_table(n_states, actions):\n",
    "    # initialize a Q-table using numpy or pandas\n",
    "    # do not change the code above\n",
    "    table = pd.DataFrame(np.zeros((n_states, len(actions))), columns = actions)\n",
    "    \n",
    "    # do not change the code below\n",
    "    return table\n",
    "\n",
    "test_table = build_q_table(N_STATES, ACTIONS)\n",
    "print(test_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cH1CszvIPXLW"
   },
   "source": [
    "### Take actions according to Q-table\n",
    "\n",
    "We will use a greedy strategy to choose actions according to Q-table. That is, most of the time (with a pre-defined probability), at each state, we will take the action with the highest value. Otherwise, we will randomly choose an action to encourage exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681653451261,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "cpvT3rueRxB7",
    "outputId": "d06b9be6-1ea9-44ef-ece9-5cc09062eb93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n"
     ]
    }
   ],
   "source": [
    "EPSILON = 0.9   # greedy police, the predefined probability\n",
    "\n",
    "def choose_action(state, q_table):\n",
    "    # do not change the code above\n",
    "    state_actions = q_table.iloc[state, :]\n",
    "    if (np.random.uniform() > EPSILON) or ((state_actions == 0). all()):\n",
    "        action_name = np.random.choice(ACTIONS)\n",
    "    else:\n",
    "        action_name = state_actions.idxmax()\n",
    "\n",
    "    # do not change the code below\n",
    "    return action_name\n",
    "\n",
    "current_state = 0\n",
    "test_action = choose_action(current_state, test_table)\n",
    "print(test_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffLkeQaDR1VT"
   },
   "source": [
    "### Environment\n",
    "\n",
    "Now, we provide the simulated 1-dimension environment, which has the following two functions:\n",
    "\n",
    "1. get_env_feedback takes current state and action as inputs, then outputs the new state and corresponding reward (i.e., only treasure state gives a reward +1, other states gives 0 reward).\n",
    "2. update_env will visualize the environment, considering current agent state (i.e., S), and output how many steps for the agent to reach the treasure (i.e., step_counter) in current episode of trail (i.e., episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1076,
     "status": "ok",
     "timestamp": 1681653539199,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "-oeMShRBR_Tb",
    "outputId": "9aa4c57a-1f91-4236-faa1-1d61352cf024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "-o---T"
     ]
    }
   ],
   "source": [
    "FRESH_TIME = 0.3    # fresh time for one move\n",
    "\n",
    "def get_env_feedback(S, A):\n",
    "    # This is how agent will interact with the environment\n",
    "    if A == 'right':    # move right\n",
    "        if S == N_STATES - 2:   # terminate\n",
    "            S_ = 'terminal'\n",
    "            R = 1\n",
    "        else:\n",
    "            S_ = S + 1\n",
    "            R = 0\n",
    "    else:   # move left\n",
    "        R = 0\n",
    "        if S == 0:\n",
    "            S_ = S  # reach the wall\n",
    "        else:\n",
    "            S_ = S - 1\n",
    "    return S_, R\n",
    "\n",
    "\n",
    "def update_env(S, episode, step_counter):\n",
    "    # This is how environment be updated\n",
    "    env_list = ['-']*(N_STATES-1) + ['T']   # '---------T' our environment\n",
    "    if S == 'terminal':\n",
    "        interaction = 'Episode %s: total_steps = %s' % (episode+1, step_counter)\n",
    "        print('\\r{}'.format(interaction), end='')\n",
    "        time.sleep(2)\n",
    "        print('\\r                                ', end='')\n",
    "    else:\n",
    "        env_list[S] = 'o'\n",
    "        interaction = ''.join(env_list)\n",
    "        print('\\r{}'.format(interaction), end='')\n",
    "        time.sleep(FRESH_TIME)\n",
    "\n",
    "next_state, reward = get_env_feedback(current_state, test_action)\n",
    "print(next_state, reward)\n",
    "update_env(current_state, 0, 0)\n",
    "update_env(next_state, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnF1cjzmTkeW"
   },
   "source": [
    "### RL main loop\n",
    "\n",
    "Remeber the algorithem?\n",
    "\n",
    "\n",
    "```\n",
    "Initialize Q(s,a)\n",
    "Repeat:\n",
    "    Initialize agent state s\n",
    "    Repeat:\n",
    "        Choose action a given s according to Q-table\n",
    "        Take action a, observe reward r and updated state s'\n",
    "        update Q-table Q(s,a) using the following equation\n",
    "        update s with new state s'\n",
    "    until s is terminal\n",
    "```\n",
    "\n",
    "$Q(s,a)←Q(s,a)+\\alpha[r+\\gamma\\max_{a'}Q(s',a')-Q(s,a)]$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34217,
     "status": "ok",
     "timestamp": 1681653585973,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "sNlwdtcaAmQr",
    "outputId": "0450be32-d0be-4c85-eaa9-88792cc43f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                \n",
      "Q-table:\n",
      "\n",
      "      left     right\n",
      "0  0.00000  0.000007\n",
      "1  0.00000  0.000572\n",
      "2  0.00003  0.006934\n",
      "3  0.00000  0.073314\n",
      "4  0.00000  0.409510\n",
      "5  0.00000  0.000000\n"
     ]
    }
   ],
   "source": [
    "ALPHA = 0.1     # learning rate\n",
    "GAMMA = 0.9    # discount factor\n",
    "MAX_EPISODES = 5   # maximum episodes\n",
    "\n",
    "def rl():\n",
    "    # main part of RL loop\n",
    "    q_table = build_q_table(N_STATES, ACTIONS)\n",
    "    for episode in range(MAX_EPISODES):\n",
    "        step_counter = 0\n",
    "        S = 0\n",
    "        is_terminated = False\n",
    "        update_env(S, episode, step_counter)\n",
    "        while not is_terminated:\n",
    "            # do not change the code above\n",
    "            # choose an action based on the epsilon-greedy policy\n",
    "            A = choose_action(S, q_table)\n",
    "            \n",
    "            # take the action and observe the reward and next state\n",
    "            S_, R = get_env_feedback(S, A)\n",
    "            \n",
    "            # update the Q-value using the Q-learning algorithm\n",
    "            q_predict = q_table.loc[S, A]\n",
    "            if S_ != 'terminal':\n",
    "                q_target = R + GAMMA * q_table.iloc[S_, :].max()\n",
    "            else:\n",
    "                q_target = R\n",
    "                is_terminated = True\n",
    "            q_table.loc[S, A] += ALPHA * (q_target - q_predict)\n",
    "            \n",
    "            # move to the next state\n",
    "            S = S_\n",
    "            \n",
    "            # do not change the code below\n",
    "            update_env(S, episode, step_counter+1)\n",
    "            step_counter += 1\n",
    "    return q_table\n",
    "\n",
    "\n",
    "q_table = rl()\n",
    "print('\\r\\nQ-table:\\n')\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIELEFOfYEeY"
   },
   "source": [
    "# Pytorch\n",
    "\n",
    "Here is a simple example to get familiar with Pytorch for writing your own neural networks. PyTorch is an open source machine learning framework that allows you to write your own neural networks and optimize them efficiently. However, PyTorch is not the only framework of its kind. Alternatives to PyTorch include [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax#quickstart-colab-in-the-cloud) and [Caffe](http://caffe.berkeleyvision.org/). Below content is simplied from [Pytorch tutorial](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.ipynb#scrollTo=t7y2I3UKXh7Z).\n",
    "\n",
    "There are also many great tutorials online, including the [\"60-min blitz\"](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) on the official [PyTorch website](https://pytorch.org/tutorials/).\n",
    "\n",
    "Let's start with importing Pytorch. The package is called `torch`, based on its original framework [Torch](http://torch.ch/). As a first step, we can check its version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6853,
     "status": "ok",
     "timestamp": 1681654488135,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "qPT7AjooYK_H",
    "outputId": "c4b21375-7180-4b0b-9a0e-96d4d40b5932"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 1.12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Using torch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1681654620432,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "yjUH2Qt2a1lT",
    "outputId": "3a27a912-1369-40c5-9dfe-f65061ff7306"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa5d8d631b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42) # Setting the seed for reproducibility, similar with numpy.random.seed as mentioned above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9zKfiE4Y_v-"
   },
   "source": [
    "### Tensors\n",
    "\n",
    "Tensors are the PyTorch equivalent to Numpy arrays, with the addition to also have support for GPU acceleration (more on that later).\n",
    "The name \"tensor\" is a generalization of concepts you already know. For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor. When working with neural networks, we will use tensors of various shapes and number of dimensions.\n",
    "\n",
    "Most common functions you know from numpy can be used on tensors as well. Actually, since numpy arrays are so similar to tensors, we can convert most tensors to numpy arrays (and back) but we don't need it too often.\n",
    "\n",
    "#### Initialization\n",
    "\n",
    "Let's first start by looking at different ways of creating a tensor. There are many possible options, the simplest one is to call `torch.Tensor` passing the desired shape as input argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1681654667905,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "6OnEItyvY-8Y",
    "outputId": "ef572431-7392-4e7b-adcd-a6867c9dcf0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000e+00, -0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [3.5873e-43, 3.6013e-43, 3.5873e-43, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 1.1704e-41, 0.0000e+00, 2.2369e+08],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [       nan,        nan, 1.7270e+18,        nan]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(2, 3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utd4xDoLZ8EG"
   },
   "source": [
    "The function `torch.Tensor` allocates memory for the desired tensor, but reuses any values that have already been in the memory. To directly assign values to the tensor during initialization, there are many alternatives including:\n",
    "\n",
    "* `torch.zeros`: Creates a tensor filled with zeros\n",
    "* `torch.ones`: Creates a tensor filled with ones\n",
    "* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n",
    "* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
    "* `torch.arange`: Creates a tensor containing the values $N,N+1,N+2,...,M$\n",
    "* `torch.Tensor` (input list): Creates a tensor from the list elements you provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1681654714974,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "TAjiAKh6blmy",
    "outputId": "7200eb97-385b-45d7-ff5b-01f7d22b3b15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor from a (nested) list\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77HeyTzJbpxK"
   },
   "source": [
    "You can obtain the shape of a tensor in the same way as in numpy (`x.shape`), or using the `.size` method.\n",
    "\n",
    "Note that shape verification is very important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ZHr14MOMbsgK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 2])\n",
      "Size: torch.Size([2, 2])\n",
      "Size: 2 2\n"
     ]
    }
   ],
   "source": [
    "shape = x.shape\n",
    "print(\"Shape:\", x.shape)\n",
    "\n",
    "size = x.size()\n",
    "print(\"Size:\", size)\n",
    "\n",
    "dim1, dim2 = x.size()\n",
    "print(\"Size:\", dim1, dim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "218ZOVGcbuSz"
   },
   "source": [
    "#### Tensor to Numpy, and Numpy to Tensor\n",
    "\n",
    "Tensors can be converted to numpy arrays, and numpy arrays back to tensors. To transform a numpy array into a tensor, we can use the function `torch.from_numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1681654859188,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "z8G73PTJYv7K",
    "outputId": "17c5f187-3c24-48e8-ffb2-e8e5d7646e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array: [[1 2]\n",
      " [3 4]]\n",
      "PyTorch tensor: tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"Numpy array:\", np_arr)\n",
    "print(\"PyTorch tensor:\", tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zoiWkyNcPPZ"
   },
   "source": [
    "To transform a PyTorch tensor back to a numpy array, we can use the function `.numpy()` on tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681654879222,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "szX9sTs2cQo5",
    "outputId": "404e36e4-f257-4ee2-ef80-2a4075cd90be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch tensor: tensor([0, 1, 2, 3])\n",
      "Numpy array: [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(4)\n",
    "np_arr = tensor.numpy()\n",
    "\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "print(\"Numpy array:\", np_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6u83dpBcWFx"
   },
   "source": [
    "The conversion of tensors to numpy require the tensor to be on the CPU, and not the GPU (more on GPU support in a later section). In case you have a tensor on GPU, you need to call `.cpu()` on the tensor beforehand. Hence, you get a line like `np_arr = tensor.cpu().numpy()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejapJvozb8Zn"
   },
   "source": [
    "### Operations\n",
    "\n",
    "Most operations that exist in numpy, also exist in PyTorch. A full list of operations can be found in the [PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#), but we will review the most important ones here.\n",
    "\n",
    "The simplest operation is to add two tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1681654934766,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "Z6kiCbvUcDh-",
    "outputId": "0bd26c7e-8b29-4f9d-86d3-3e97f7277125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009]])\n",
      "X2 tensor([[0.2566, 0.7936, 0.9408],\n",
      "        [0.1332, 0.9346, 0.5936]])\n",
      "Y tensor([[1.1388, 1.7086, 1.3236],\n",
      "        [1.0925, 1.3250, 1.1945]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand(2, 3)\n",
    "x2 = torch.rand(2, 3)\n",
    "y = x1 + x2\n",
    "\n",
    "print(\"X1\", x1)\n",
    "print(\"X2\", x2)\n",
    "print(\"Y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7S0sJdScnlv"
   },
   "source": [
    "Another common operation aims at changing the shape of a tensor. A tensor of size (2,3) can be re-organized to any other shape with the same number of elements (e.g. a tensor of size (6), or (3,2), ...). In PyTorch, this operation is called `view`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681654995032,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "M8Dbq3TZcppt",
    "outputId": "d7f2070f-03ae-430b-a104-9b43530dd777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([0, 1, 2, 3, 4, 5])\n",
      "X tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "X tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "print(\"X\", x)\n",
    "\n",
    "x = x.view(2, 3)\n",
    "print(\"X\", x)\n",
    "\n",
    "x = x.permute(1, 0) # Swapping dimension 0 and 1\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24XBMgFSc6Ca"
   },
   "source": [
    "Other commonly used operations include matrix multiplications, which are essential for neural networks. Quite often, we have an input vector $\\mathbf{x}$, which is transformed using a learned weight matrix $\\mathbf{W}$. There are multiple ways and functions to perform matrix multiplication, some of which we list below:\n",
    "\n",
    "* `torch.matmul`: Performs the matrix product over two tensors, where the specific behavior depends on the dimensions. If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product. For higher dimensional inputs, the function supports broadcasting (for details see the [documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul)). Can also be written as `a @ b`, similar to numpy. \n",
    "* `torch.mm`: Performs the matrix product over two matrices, but doesn't support broadcasting (see [documentation](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm))\n",
    "* `torch.bmm`: Performs the matrix product with a support batch dimension. If the first tensor $T$ is of shape ($b\\times n\\times m$), and the second tensor $R$ ($b\\times m\\times p$), the output $O$ is of shape ($b\\times n\\times p$), and has been calculated by performing $b$ matrix multiplications of the submatrices of $T$ and $R$: $O_i = T_i @ R_i$\n",
    "* `torch.einsum`: Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention. Explanation of the Einstein sum can be found in assignment 1.\n",
    "\n",
    "Usually, we use `torch.matmul` or `torch.bmm`. We can try a matrix multiplication with `torch.matmul` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1681655087682,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "8fQbIK0qc-vb",
    "outputId": "9b76e883-1896-49f8-c664-a9068db7954b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "W tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "h tensor([[15, 18, 21],\n",
      "        [42, 54, 66]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "x = x.view(2, 3)\n",
    "print(\"X\", x)\n",
    "\n",
    "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
    "print(\"W\", W)\n",
    "\n",
    "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
    "print(\"h\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyXj4spXdKqo"
   },
   "source": [
    "### Indexing\n",
    "\n",
    "We often have the situation where we need to select a part of a tensor. Indexing works just like in numpy, so let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1681655162880,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "TIAGtTRCdN4y",
    "outputId": "01ebedde-af7f-490a-df42-6cfdb21f5460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([1, 5, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([3, 7])\n",
      "tensor([[ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).view(3, 4)\n",
    "print(\"X\", x)\n",
    "\n",
    "print(x[:, 1])   # Second column\n",
    "\n",
    "print(x[0])      # First row\n",
    "\n",
    "print(x[:2, -1]) # First two rows, last column\n",
    "\n",
    "print(x[1:3, :]) # Middle two rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuameqWJdb_4"
   },
   "source": [
    "### Dynamic Computation Graph and Backpropagation\n",
    "\n",
    "One of the main reasons for using PyTorch in Deep Learning projects is that we can automatically get **gradients/derivatives** of functions that we define. We will mainly use PyTorch for implementing neural networks, and they are just fancy functions. If we use weight matrices in our function that we want to learn, then those are called the **parameters** or simply the **weights**.\n",
    "\n",
    "If our neural network would output a single scalar value, we would talk about taking the **derivative**, but you will see that quite often we will have **multiple** output variables (\"values\"); in that case we talk about **gradients**. It's a more general term.\n",
    "\n",
    "Given an input $\\mathbf{x}$, we define our function by **manipulating** that input, usually by matrix-multiplications with weight matrices and additions with so-called bias vectors. As we manipulate our input, we are automatically creating a **computational graph**. This graph shows how to arrive at our output from our input. \n",
    "PyTorch is a **define-by-run** framework; this means that we can just do our manipulations, and PyTorch will keep track of that graph for us. Thus, we create a dynamic computation graph along the way.\n",
    "\n",
    "So, to recap: the only thing we have to do is to compute the **output**, and then we can ask PyTorch to automatically get the **gradients**. \n",
    "\n",
    "> **Note:  Why do we want gradients?** Consider that we have defined a function, a neural net, that is supposed to compute a certain output $y$ for an input vector $\\mathbf{x}$. We then define an **error measure** that tells us how wrong our network is; how bad it is in predicting output $y$ from input $\\mathbf{x}$. Based on this error measure, we can use the gradients to **update** the weights $\\mathbf{W}$ that were responsible for the output, so that the next time we present input $\\mathbf{x}$ to our network, the output will be closer to what we want.\n",
    "\n",
    "The first thing we have to do is to specify which tensors require gradients. By default, when we create a tensor, it does not require gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1681655217237,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "VdAeIdpkdi-9",
    "outputId": "0a990661-337c-423c-ef14-9646dbade8f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((3,))\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWTF-tkMzfnR"
   },
   "source": [
    "We can change this for an existing tensor using the function `requires_grad_()` (underscore indicating that this is a in-place operation). Alternatively, when creating a tensor, you can pass the argument `requires_grad=True` to most initializers we have seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681655238824,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "44DYa6D6dm4M",
    "outputId": "7b871fc5-cfd9-4070-f613-19ed9c9ebddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(True)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqXwepIQzN2p"
   },
   "source": [
    "## Learning by example: Continuous XOR\n",
    "\n",
    "If we want to build a neural network in PyTorch, we could specify all our parameters (weight matrices, bias vectors) using `Tensors` (with `requires_grad=True`), ask PyTorch to calculate the gradients and then adjust the parameters. But things can quickly get cumbersome if we have a lot of parameters. In PyTorch, there is a package called `torch.nn` that makes building neural networks more convenient. \n",
    "\n",
    "We will introduce the libraries and all additional parts you might need to train a neural network in PyTorch, using a simple example classifier on a simple yet well known example: XOR. Given two binary inputs $x_1$ and $x_2$, the label to predict is $1$ if either $x_1$ or $x_2$ is $1$ while the other is $0$, or the label is $0$ in all other cases.\n",
    "\n",
    "| x1 | x2 | XOR |\n",
    "|----|:--:|----:|\n",
    "| 0  |  0 |  0  |\n",
    "| 0  |  1 |  1  |\n",
    "| 1  |  0 |  1  |\n",
    "| 1  |  1 |  0  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LG6IZuAtfjS6"
   },
   "source": [
    "### The model\n",
    "\n",
    "The package `torch.nn` defines a series of useful classes like linear networks layers, activation functions, loss functions etc. A full list can be found [here](https://pytorch.org/docs/stable/nn.html). In case you need a certain network layer, check the documentation of the package first before writing the layer yourself as the package likely contains the code for it already. We import it below.\n",
    "\n",
    "Additionally to `torch.nn`, there is also `torch.nn.functional`. It contains functions that are used in network layers. This is in contrast to `torch.nn` which defines them as `nn.Modules` (more on it below), and `torch.nn` actually uses a lot of functionalities from `torch.nn.functional`. Hence, the functional package is useful in many situations, and so we import it as well here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "qoG4aaQ18ST_"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFIDknzPzSop"
   },
   "source": [
    "### nn.Module\n",
    "\n",
    "In PyTorch, a neural network is built up out of modules. Modules can contain other modules, and a neural network is considered to be a module itself as well. The basic template of a module is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "fxRSmOMTwcvI"
   },
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Some init for my module\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Function for performing the calculation of the module.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbDMa6H7101u"
   },
   "source": [
    "The forward function is where the computation of the module is taken place, and is executed when you call the module (`nn = MyModule(); nn(x)`). In the init function, we usually create the parameters of the module, using `nn.Parameter`, or defining other modules that are used in the forward function. The backward calculation is done automatically, but could be overwritten as well if wanted.\n",
    "\n",
    "Let's build a simple classifier for XOR function!\n",
    "\n",
    "We will take two input neurons, four hidden neurons, and a single output neuron for binary classification. We will apply a Tanh as the activation function. The architecture is as follows:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "SimpleClassifier(\n",
    "  (linear1): Linear(in_features=2, out_features=4, bias=True)\n",
    "  (act_fn): Tanh()\n",
    "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Ske0iL2F0FYi"
   },
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        # Initialize the modules we need to build the network\n",
    "        # do not change the code above\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "        \n",
    "        # do not change the code below\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        # do not change the code above\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        # do not change the code below\n",
    "        return x.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681656110424,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "al_sKfOFg9It",
    "outputId": "276c19fb-a820-416b-d222-b06120fcfa35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier(\n",
      "  (linear1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (act_fn): Tanh()\n",
      "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "# Printing a module shows all its submodules\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VEsUk7khDYS"
   },
   "source": [
    "Printing the model lists all submodules it contains. The parameters of a module can be obtained by using its `parameters()` functions, or `named_parameters()` to get a name to each parameter object. For our small neural network, we have the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681656146039,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "KMTbXLrahC4h",
    "outputId": "899eeee5-bc72-4e22-d236-544d050feef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter linear1.weight, shape torch.Size([4, 2])\n",
      "Parameter linear1.bias, shape torch.Size([4])\n",
      "Parameter linear2.weight, shape torch.Size([1, 4])\n",
      "Parameter linear2.bias, shape torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXCZLIYqhX0N"
   },
   "source": [
    "Each linear layer has a weight matrix of the shape `[output, input]`, and a bias of the shape `[output]`. The tanh activation function does not have any parameters. Note that parameters are only registered for `nn.Module` objects that are direct object attributes, i.e. `self.a = ...`. If you define a list of modules, the parameters of those are not registered for the outer module and can cause some issues when you try to optimize your module. There are alternatives, like `nn.ModuleList`, `nn.ModuleDict` and `nn.Sequential`, that allow you to have different data structures of modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uP1wc3a4-CB"
   },
   "source": [
    "### Datasets\n",
    "\n",
    "We provide XOR dataset for training and evaluating the above model.\n",
    "\n",
    "PyTorch also provides a few functionalities to load the training and test data efficiently, summarized in the package `torch.utils.data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "2Cl7oBb7iG_N"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class XORDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, size, std=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.std = std\n",
    "        self.generate_continuous_xor()\n",
    "\n",
    "    def generate_continuous_xor(self):\n",
    "        # Each data point in the XOR dataset has two variables, x and y, that can be either 0 or 1\n",
    "        # The label is their XOR combination, i.e. 1 if only x or only y is 1 while the other is 0.\n",
    "        # If x=y, the label is 0.\n",
    "        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n",
    "        label = (data.sum(dim=1) == 1).to(torch.long)\n",
    "        # To make it slightly more challenging, we add a bit of gaussian noise to the data points.\n",
    "        data += self.std * torch.randn(data.shape)\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the idx-th data point of the dataset\n",
    "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681656438787,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "F0OWh-hFiJFm",
    "outputId": "23aeed69-2723-4394-ed2e-a47ab099af77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 200\n",
      "Data point 0: (tensor([ 0.8597, -0.1327]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "dataset = XORDataset(size=200)\n",
    "print(\"Size of dataset:\", len(dataset))\n",
    "print(\"Data point 0:\", dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3315,
     "status": "ok",
     "timestamp": 1681656515568,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "QofaSbTdiQK4",
    "outputId": "1e74df05-c673-4fdf-ebec-05d6efc66f7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/8_w0j87d1350zx_gm7nwg9f80000gn/T/ipykernel_42045/1903200412.py:5: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "def visualize_samples(data, label):\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        data = data.cpu().numpy()\n",
    "    if isinstance(label, torch.Tensor):\n",
    "        label = label.cpu().numpy()\n",
    "    data_0 = data[label == 0]\n",
    "    data_1 = data[label == 1]\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
    "    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
    "    plt.title(\"Dataset samples\")\n",
    "    plt.ylabel(r\"$x_2$\")\n",
    "    plt.xlabel(r\"$x_1$\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "executionInfo": {
     "elapsed": 2679,
     "status": "ok",
     "timestamp": 1681656521568,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "boDVjaJziSad",
    "outputId": "51dc5a4b-c55a-400a-e573-e5a27ce929f3"
   },
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"283.789063pt\" height=\"285.283594pt\" viewBox=\"0 0 283.789063 285.283594\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-04-22T12:30:43.465577</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.0, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 285.283594 \n",
       "L 283.789063 285.283594 \n",
       "L 283.789063 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 53.389062 243.549375 \n",
       "L 276.589063 243.549375 \n",
       "L 276.589063 21.789375 \n",
       "L 53.389062 21.789375 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 104.737692 243.549375 \n",
       "L 104.737692 21.789375 \n",
       "\" clip-path=\"url(#p298a4fa963)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(97.092692 260.922969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-2e\" d=\"M 581 0 \n",
       "L 581 641 \n",
       "L 1222 641 \n",
       "L 1222 0 \n",
       "L 581 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path d=\"M 171.160013 243.549375 \n",
       "L 171.160013 21.789375 \n",
       "\" clip-path=\"url(#p298a4fa963)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.5 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(163.515013 260.922969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
       "L 856 1250 \n",
       "Q 922 819 1161 601 \n",
       "Q 1400 384 1738 384 \n",
       "Q 2144 384 2425 690 \n",
       "Q 2706 997 2706 1503 \n",
       "Q 2706 1984 2436 2262 \n",
       "Q 2166 2541 1728 2541 \n",
       "Q 1456 2541 1237 2417 \n",
       "Q 1019 2294 894 2097 \n",
       "L 366 2166 \n",
       "L 809 4519 \n",
       "L 3088 4519 \n",
       "L 3088 3981 \n",
       "L 1259 3981 \n",
       "L 1013 2750 \n",
       "Q 1425 3038 1878 3038 \n",
       "Q 2478 3038 2890 2622 \n",
       "Q 3303 2206 3303 1553 \n",
       "Q 3303 931 2941 478 \n",
       "Q 2500 -78 1738 -78 \n",
       "Q 1113 -78 717 272 \n",
       "Q 322 622 266 1200 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 237.582335 243.549375 \n",
       "L 237.582335 21.789375 \n",
       "\" clip-path=\"url(#p298a4fa963)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 1.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(229.937335 260.922969) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_4\">\n",
       "     <!-- $x_1$ -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(158.569063 275.698594) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-Oblique-78\" d=\"M 3841 3500 \n",
       "L 2234 1784 \n",
       "L 3219 0 \n",
       "L 2559 0 \n",
       "L 1819 1388 \n",
       "L 531 0 \n",
       "L -166 0 \n",
       "L 1556 1844 \n",
       "L 641 3500 \n",
       "L 1300 3500 \n",
       "L 1972 2234 \n",
       "L 3144 3500 \n",
       "L 3841 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(0 0.3125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(59.179688 -16.09375) scale(0.7)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path d=\"M 53.389062 232.500163 \n",
       "L 276.589063 232.500163 \n",
       "\" clip-path=\"url(#p298a4fa963)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- −0.2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(22.174375 236.43696) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-2212\" d=\"M 3381 1997 \n",
       "L 356 1997 \n",
       "L 356 2522 \n",
       "L 3381 2522 \n",
       "L 3381 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"58.398438\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"114.013672\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"141.796875\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 53.389062 205.449979 \n",
       "L 276.589063 205.449979 \n",
       "\" clip-path=\"url(#p298a4fa963)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(28.599062 209.386776) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path d=\"M 53.389062 178.399795 \n",
       "L 276.589063 178.399795 \n",
       "\" clip-path=\"url(#p298a4fa963)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(28.599062 182.336591) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 53.389062 151.349611 \n",
       "L 276.589063 151.349611 \n",
       "\" clip-path=\"url(#p298a4fa963)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.4 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(28.599062 155.286407) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path d=\"M 53.389062 124.299427 \n",
       "L 276.589063 124.299427 \n",
       "\" clip-path=\"url(#p298a4fa963)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.6 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(28.599062 128.236223) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-36\" d=\"M 3184 3459 \n",
       "L 2625 3416 \n",
       "Q 2550 3747 2413 3897 \n",
       "Q 2184 4138 1850 4138 \n",
       "Q 1581 4138 1378 3988 \n",
       "Q 1113 3794 959 3422 \n",
       "Q 806 3050 800 2363 \n",
       "Q 1003 2672 1297 2822 \n",
       "Q 1591 2972 1913 2972 \n",
       "Q 2475 2972 2870 2558 \n",
       "Q 3266 2144 3266 1488 \n",
       "Q 3266 1056 3080 686 \n",
       "Q 2894 316 2569 119 \n",
       "Q 2244 -78 1831 -78 \n",
       "Q 1128 -78 684 439 \n",
       "Q 241 956 241 2144 \n",
       "Q 241 3472 731 4075 \n",
       "Q 1159 4600 1884 4600 \n",
       "Q 2425 4600 2770 4297 \n",
       "Q 3116 3994 3184 3459 \n",
       "z\n",
       "M 888 1484 \n",
       "Q 888 1194 1011 928 \n",
       "Q 1134 663 1356 523 \n",
       "Q 1578 384 1822 384 \n",
       "Q 2178 384 2434 671 \n",
       "Q 2691 959 2691 1453 \n",
       "Q 2691 1928 2437 2201 \n",
       "Q 2184 2475 1800 2475 \n",
       "Q 1419 2475 1153 2201 \n",
       "Q 888 1928 888 1484 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 53.389062 97.249242 \n",
       "L 276.589063 97.249242 \n",
       "\" clip-path=\"url(#p298a4fa963)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.8 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(28.599062 101.186039) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-38\" d=\"M 1131 2484 \n",
       "Q 781 2613 612 2850 \n",
       "Q 444 3088 444 3419 \n",
       "Q 444 3919 803 4259 \n",
       "Q 1163 4600 1759 4600 \n",
       "Q 2359 4600 2725 4251 \n",
       "Q 3091 3903 3091 3403 \n",
       "Q 3091 3084 2923 2848 \n",
       "Q 2756 2613 2416 2484 \n",
       "Q 2838 2347 3058 2040 \n",
       "Q 3278 1734 3278 1309 \n",
       "Q 3278 722 2862 322 \n",
       "Q 2447 -78 1769 -78 \n",
       "Q 1091 -78 675 323 \n",
       "Q 259 725 259 1325 \n",
       "Q 259 1772 486 2073 \n",
       "Q 713 2375 1131 2484 \n",
       "z\n",
       "M 1019 3438 \n",
       "Q 1019 3113 1228 2906 \n",
       "Q 1438 2700 1772 2700 \n",
       "Q 2097 2700 2305 2904 \n",
       "Q 2513 3109 2513 3406 \n",
       "Q 2513 3716 2298 3927 \n",
       "Q 2084 4138 1766 4138 \n",
       "Q 1444 4138 1231 3931 \n",
       "Q 1019 3725 1019 3438 \n",
       "z\n",
       "M 838 1322 \n",
       "Q 838 1081 952 856 \n",
       "Q 1066 631 1291 507 \n",
       "Q 1516 384 1775 384 \n",
       "Q 2178 384 2440 643 \n",
       "Q 2703 903 2703 1303 \n",
       "Q 2703 1709 2433 1975 \n",
       "Q 2163 2241 1756 2241 \n",
       "Q 1359 2241 1098 1978 \n",
       "Q 838 1716 838 1322 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path d=\"M 53.389062 70.199058 \n",
       "L 276.589063 70.199058 \n",
       "\" clip-path=\"url(#p298a4fa963)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1.0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(28.599062 74.135855) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 53.389062 43.148874 \n",
       "L 276.589063 43.148874 \n",
       "\" clip-path=\"url(#p298a4fa963)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.2 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(28.599062 47.085671) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- $x_2$ -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(15.789375 139.089375) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(0 0.3125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(59.179688 -16.09375) scale(0.7)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"me584df1ed5\" d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" style=\"stroke: #333333\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p298a4fa963)\">\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"252.681628\" y=\"76.445487\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"103.8406\" y=\"192.613767\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"99.445999\" y=\"196.118993\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"222.036703\" y=\"71.594655\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"229.181993\" y=\"75.08861\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"219.9255\" y=\"48.675277\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"103.132752\" y=\"211.982878\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"106.242794\" y=\"204.406505\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"121.331299\" y=\"186.252764\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"106.756001\" y=\"190.617806\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"228.499836\" y=\"69.305819\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"229.444013\" y=\"76.739106\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"228.051866\" y=\"31.869375\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"236.613018\" y=\"77.610201\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"222.404129\" y=\"76.268471\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"236.744087\" y=\"83.192355\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"248.62693\" y=\"54.240236\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"233.179491\" y=\"61.414448\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"105.999165\" y=\"215.628791\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"253.378458\" y=\"77.885407\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"226.288492\" y=\"83.235203\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"203.483849\" y=\"60.601486\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"248.473507\" y=\"61.793939\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"239.838756\" y=\"81.971364\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"99.601111\" y=\"229.669048\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"242.427297\" y=\"59.523491\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"220.415737\" y=\"59.835539\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"113.311488\" y=\"200.671346\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"103.972197\" y=\"223.26432\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"106.839116\" y=\"202.014185\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"102.358991\" y=\"189.229545\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"236.577663\" y=\"93.70029\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"103.072455\" y=\"223.922748\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"119.506645\" y=\"213.87336\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"87.051422\" y=\"178.30392\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"88.090906\" y=\"190.317163\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"242.634373\" y=\"67.507828\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"149.696798\" y=\"199.040381\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"246.22171\" y=\"54.425588\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"104.962678\" y=\"198.246693\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"256.291469\" y=\"98.177589\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"89.847124\" y=\"202.80392\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"94.355642\" y=\"229.658258\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"100.310515\" y=\"211.943337\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"105.187966\" y=\"209.673779\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"75.7542\" y=\"204.621207\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"105.870339\" y=\"195.331516\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"235.409505\" y=\"82.48737\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"93.700873\" y=\"198.712283\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"223.799879\" y=\"95.540387\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"135.636107\" y=\"217.898352\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"113.586672\" y=\"211.404602\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"102.693433\" y=\"213.134898\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"103.693676\" y=\"199.620044\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"237.230618\" y=\"75.795554\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"246.947472\" y=\"84.857709\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"232.415658\" y=\"59.208428\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"257.484038\" y=\"69.605355\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"227.10879\" y=\"87.493548\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"109.225777\" y=\"203.758584\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"112.625127\" y=\"199.286325\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"92.351301\" y=\"187.154677\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"106.866901\" y=\"211.056979\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"228.412894\" y=\"73.309241\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"75.880063\" y=\"204.264055\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"76.903461\" y=\"218.347785\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"236.35388\" y=\"83.949402\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"218.877825\" y=\"41.395683\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"247.668231\" y=\"107.98315\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"228.13503\" y=\"63.118377\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"137.938246\" y=\"209.53394\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"107.669476\" y=\"203.403227\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"141.020635\" y=\"199.607068\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"235.531073\" y=\"73.081832\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"225.785428\" y=\"71.669846\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"99.172768\" y=\"185.994966\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"97.887265\" y=\"215.636849\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"236.845645\" y=\"65.843579\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"254.592961\" y=\"71.77014\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"229.687868\" y=\"67.538075\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"104.8467\" y=\"210.939275\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"102.802377\" y=\"210.662872\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"248.343618\" y=\"57.221828\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"265.375148\" y=\"59.442424\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"111.79085\" y=\"223.86413\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"263.570061\" y=\"46.280067\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"124.211793\" y=\"205.46362\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"226.298168\" y=\"92.64249\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"115.343305\" y=\"179.900778\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"218.561297\" y=\"78.410506\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"239.414771\" y=\"63.120666\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"248.770248\" y=\"73.050005\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"115.380594\" y=\"205.221169\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"122.611739\" y=\"203.734701\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"103.456337\" y=\"186.588641\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"242.203166\" y=\"60.188088\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"247.656353\" y=\"77.430347\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"247.002567\" y=\"73.776144\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"197.94707\" y=\"75.806559\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"224.296537\" y=\"79.557782\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"123.747886\" y=\"200.481823\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"104.482247\" y=\"219.877773\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"211.154984\" y=\"66.177876\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"243.35388\" y=\"70.153156\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"230.197117\" y=\"47.392582\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#me584df1ed5\" x=\"100.490173\" y=\"217.799638\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_2\">\n",
       "    <defs>\n",
       "     <path id=\"mde6b2d7519\" d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" style=\"stroke: #333333\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p298a4fa963)\">\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"218.939713\" y=\"223.398692\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"91.522905\" y=\"76.880442\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"123.601359\" y=\"58.722766\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"87.296055\" y=\"69.687761\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"82.264848\" y=\"88.916216\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"244.050155\" y=\"219.002523\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"238.020035\" y=\"211.254892\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"231.751411\" y=\"210.85874\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"104.727408\" y=\"68.007178\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"230.383652\" y=\"219.782791\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"241.643795\" y=\"199.836279\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"241.198352\" y=\"204.626907\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"221.940695\" y=\"183.51641\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"248.890937\" y=\"210.866372\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"229.494388\" y=\"212.322017\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"111.776403\" y=\"82.508652\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"113.854955\" y=\"76.289488\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"118.148417\" y=\"58.099235\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"100.914456\" y=\"88.64417\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"240.14568\" y=\"213.704806\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"239.750817\" y=\"185.024767\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"105.142974\" y=\"63.143093\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"98.575462\" y=\"67.732391\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"87.015495\" y=\"52.023349\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"99.035768\" y=\"56.534869\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"97.810971\" y=\"80.445024\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"250.699634\" y=\"196.773608\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"261.139377\" y=\"233.469375\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"244.054051\" y=\"185.271141\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"237.758545\" y=\"180.300099\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"139.571509\" y=\"65.207584\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"120.908906\" y=\"62.301093\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"249.120801\" y=\"216.313539\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"112.743183\" y=\"81.508492\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"87.638286\" y=\"60.205598\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"254.83334\" y=\"193.322457\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"244.397651\" y=\"222.375869\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"221.641571\" y=\"203.730762\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"110.587719\" y=\"61.573132\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"109.573547\" y=\"74.002336\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"103.584661\" y=\"81.672948\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"126.643002\" y=\"48.551225\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"95.760419\" y=\"67.436531\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"244.469121\" y=\"214.938328\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"231.838915\" y=\"203.536488\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"92.622339\" y=\"65.218919\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"236.887738\" y=\"207.967202\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"104.227204\" y=\"44.314718\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"247.45102\" y=\"209.591374\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"108.063196\" y=\"88.608022\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"128.674093\" y=\"71.204539\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"226.869368\" y=\"204.459927\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"237.480365\" y=\"212.458963\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"99.856135\" y=\"56.515134\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"217.414557\" y=\"203.573666\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"221.909893\" y=\"212.614777\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"241.455929\" y=\"201.42355\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"82.013951\" y=\"58.858475\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"247.404778\" y=\"201.756234\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"228.19231\" y=\"222.382737\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"110.663316\" y=\"49.600891\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"99.340679\" y=\"88.649733\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"228.135941\" y=\"210.178072\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"106.112767\" y=\"58.986299\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"234.150906\" y=\"216.158441\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"110.984234\" y=\"68.973166\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"260.727268\" y=\"222.572767\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"109.907485\" y=\"65.561649\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"84.360616\" y=\"82.025328\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"266.443608\" y=\"202.403654\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"103.711529\" y=\"56.867457\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"254.564344\" y=\"201.552698\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"226.657447\" y=\"225.386255\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"232.92995\" y=\"199.241745\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"102.701765\" y=\"59.047954\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"108.806599\" y=\"54.211794\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"211.075225\" y=\"189.081076\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"102.969463\" y=\"59.049438\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"245.466175\" y=\"204.507896\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"100.278653\" y=\"87.232143\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"234.751815\" y=\"200.792435\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"63.534517\" y=\"89.928412\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"260.333989\" y=\"196.706778\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"93.828808\" y=\"76.567604\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"112.730188\" y=\"74.020047\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"238.648784\" y=\"195.375931\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"87.461173\" y=\"80.13554\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"238.175579\" y=\"226.023266\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"102.801368\" y=\"57.738398\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"244.599786\" y=\"205.561268\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"85.48409\" y=\"78.384209\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"256.922783\" y=\"200.964335\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"117.869718\" y=\"51.702401\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     <use xlink:href=\"#mde6b2d7519\" x=\"263.077995\" y=\"227.786493\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 53.389062 243.549375 \n",
       "L 53.389062 21.789375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 276.589063 243.549375 \n",
       "L 276.589063 21.789375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 53.389062 243.549375 \n",
       "L 276.589063 243.549375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 53.389062 21.789375 \n",
       "L 276.589063 21.789375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_14\">\n",
       "    <!-- Dataset samples -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(120.305 15.789375) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-44\" d=\"M 494 0 \n",
       "L 494 4581 \n",
       "L 2072 4581 \n",
       "Q 2606 4581 2888 4516 \n",
       "Q 3281 4425 3559 4188 \n",
       "Q 3922 3881 4101 3404 \n",
       "Q 4281 2928 4281 2316 \n",
       "Q 4281 1794 4159 1391 \n",
       "Q 4038 988 3847 723 \n",
       "Q 3656 459 3429 307 \n",
       "Q 3203 156 2883 78 \n",
       "Q 2563 0 2147 0 \n",
       "L 494 0 \n",
       "z\n",
       "M 1100 541 \n",
       "L 2078 541 \n",
       "Q 2531 541 2789 625 \n",
       "Q 3047 709 3200 863 \n",
       "Q 3416 1078 3536 1442 \n",
       "Q 3656 1806 3656 2325 \n",
       "Q 3656 3044 3420 3430 \n",
       "Q 3184 3816 2847 3947 \n",
       "Q 2603 4041 2063 4041 \n",
       "L 1100 4041 \n",
       "L 1100 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
       "Q 2275 144 1986 34 \n",
       "Q 1697 -75 1366 -75 \n",
       "Q 819 -75 525 192 \n",
       "Q 231 459 231 875 \n",
       "Q 231 1119 342 1320 \n",
       "Q 453 1522 633 1644 \n",
       "Q 813 1766 1038 1828 \n",
       "Q 1203 1872 1538 1913 \n",
       "Q 2219 1994 2541 2106 \n",
       "Q 2544 2222 2544 2253 \n",
       "Q 2544 2597 2384 2738 \n",
       "Q 2169 2928 1744 2928 \n",
       "Q 1347 2928 1158 2789 \n",
       "Q 969 2650 878 2297 \n",
       "L 328 2372 \n",
       "Q 403 2725 575 2942 \n",
       "Q 747 3159 1072 3276 \n",
       "Q 1397 3394 1825 3394 \n",
       "Q 2250 3394 2515 3294 \n",
       "Q 2781 3194 2906 3042 \n",
       "Q 3031 2891 3081 2659 \n",
       "Q 3109 2516 3109 2141 \n",
       "L 3109 1391 \n",
       "Q 3109 606 3145 398 \n",
       "Q 3181 191 3288 0 \n",
       "L 2700 0 \n",
       "Q 2613 175 2588 409 \n",
       "z\n",
       "M 2541 1666 \n",
       "Q 2234 1541 1622 1453 \n",
       "Q 1275 1403 1131 1340 \n",
       "Q 988 1278 909 1158 \n",
       "Q 831 1038 831 891 \n",
       "Q 831 666 1001 516 \n",
       "Q 1172 366 1500 366 \n",
       "Q 1825 366 2078 508 \n",
       "Q 2331 650 2450 897 \n",
       "Q 2541 1088 2541 1459 \n",
       "L 2541 1666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-74\" d=\"M 1650 503 \n",
       "L 1731 6 \n",
       "Q 1494 -44 1306 -44 \n",
       "Q 1000 -44 831 53 \n",
       "Q 663 150 594 308 \n",
       "Q 525 466 525 972 \n",
       "L 525 2881 \n",
       "L 113 2881 \n",
       "L 113 3319 \n",
       "L 525 3319 \n",
       "L 525 4141 \n",
       "L 1084 4478 \n",
       "L 1084 3319 \n",
       "L 1650 3319 \n",
       "L 1650 2881 \n",
       "L 1084 2881 \n",
       "L 1084 941 \n",
       "Q 1084 700 1114 631 \n",
       "Q 1144 563 1211 522 \n",
       "Q 1278 481 1403 481 \n",
       "Q 1497 481 1650 503 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-73\" d=\"M 197 991 \n",
       "L 753 1078 \n",
       "Q 800 744 1014 566 \n",
       "Q 1228 388 1613 388 \n",
       "Q 2000 388 2187 545 \n",
       "Q 2375 703 2375 916 \n",
       "Q 2375 1106 2209 1216 \n",
       "Q 2094 1291 1634 1406 \n",
       "Q 1016 1563 777 1677 \n",
       "Q 538 1791 414 1992 \n",
       "Q 291 2194 291 2438 \n",
       "Q 291 2659 392 2848 \n",
       "Q 494 3038 669 3163 \n",
       "Q 800 3259 1026 3326 \n",
       "Q 1253 3394 1513 3394 \n",
       "Q 1903 3394 2198 3281 \n",
       "Q 2494 3169 2634 2976 \n",
       "Q 2775 2784 2828 2463 \n",
       "L 2278 2388 \n",
       "Q 2241 2644 2061 2787 \n",
       "Q 1881 2931 1553 2931 \n",
       "Q 1166 2931 1000 2803 \n",
       "Q 834 2675 834 2503 \n",
       "Q 834 2394 903 2306 \n",
       "Q 972 2216 1119 2156 \n",
       "Q 1203 2125 1616 2013 \n",
       "Q 2213 1853 2448 1751 \n",
       "Q 2684 1650 2818 1456 \n",
       "Q 2953 1263 2953 975 \n",
       "Q 2953 694 2789 445 \n",
       "Q 2625 197 2315 61 \n",
       "Q 2006 -75 1616 -75 \n",
       "Q 969 -75 630 194 \n",
       "Q 291 463 197 991 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
       "L 3275 997 \n",
       "Q 3138 488 2766 206 \n",
       "Q 2394 -75 1816 -75 \n",
       "Q 1088 -75 661 373 \n",
       "Q 234 822 234 1631 \n",
       "Q 234 2469 665 2931 \n",
       "Q 1097 3394 1784 3394 \n",
       "Q 2450 3394 2872 2941 \n",
       "Q 3294 2488 3294 1666 \n",
       "Q 3294 1616 3291 1516 \n",
       "L 816 1516 \n",
       "Q 847 969 1125 678 \n",
       "Q 1403 388 1819 388 \n",
       "Q 2128 388 2347 550 \n",
       "Q 2566 713 2694 1069 \n",
       "z\n",
       "M 847 1978 \n",
       "L 2700 1978 \n",
       "Q 2663 2397 2488 2606 \n",
       "Q 2219 2931 1791 2931 \n",
       "Q 1403 2931 1139 2672 \n",
       "Q 875 2413 847 1978 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-6d\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 925 3319 \n",
       "L 925 2853 \n",
       "Q 1081 3097 1340 3245 \n",
       "Q 1600 3394 1931 3394 \n",
       "Q 2300 3394 2536 3241 \n",
       "Q 2772 3088 2869 2813 \n",
       "Q 3263 3394 3894 3394 \n",
       "Q 4388 3394 4653 3120 \n",
       "Q 4919 2847 4919 2278 \n",
       "L 4919 0 \n",
       "L 4359 0 \n",
       "L 4359 2091 \n",
       "Q 4359 2428 4304 2576 \n",
       "Q 4250 2725 4106 2815 \n",
       "Q 3963 2906 3769 2906 \n",
       "Q 3419 2906 3187 2673 \n",
       "Q 2956 2441 2956 1928 \n",
       "L 2956 0 \n",
       "L 2394 0 \n",
       "L 2394 2156 \n",
       "Q 2394 2531 2256 2718 \n",
       "Q 2119 2906 1806 2906 \n",
       "Q 1569 2906 1367 2781 \n",
       "Q 1166 2656 1075 2415 \n",
       "Q 984 2175 984 1722 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-70\" d=\"M 422 -1272 \n",
       "L 422 3319 \n",
       "L 934 3319 \n",
       "L 934 2888 \n",
       "Q 1116 3141 1344 3267 \n",
       "Q 1572 3394 1897 3394 \n",
       "Q 2322 3394 2647 3175 \n",
       "Q 2972 2956 3137 2557 \n",
       "Q 3303 2159 3303 1684 \n",
       "Q 3303 1175 3120 767 \n",
       "Q 2938 359 2589 142 \n",
       "Q 2241 -75 1856 -75 \n",
       "Q 1575 -75 1351 44 \n",
       "Q 1128 163 984 344 \n",
       "L 984 -1272 \n",
       "L 422 -1272 \n",
       "z\n",
       "M 931 1641 \n",
       "Q 931 1000 1190 694 \n",
       "Q 1450 388 1819 388 \n",
       "Q 2194 388 2461 705 \n",
       "Q 2728 1022 2728 1688 \n",
       "Q 2728 2322 2467 2637 \n",
       "Q 2206 2953 1844 2953 \n",
       "Q 1484 2953 1207 2617 \n",
       "Q 931 2281 931 1641 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-6c\" d=\"M 409 0 \n",
       "L 409 4581 \n",
       "L 972 4581 \n",
       "L 972 0 \n",
       "L 409 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-44\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" x=\"72.216797\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" x=\"127.832031\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" x=\"155.615234\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" x=\"211.230469\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" x=\"261.230469\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" x=\"316.845703\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" x=\"344.628906\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" x=\"372.412109\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" x=\"422.412109\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" x=\"478.027344\"/>\n",
       "     <use xlink:href=\"#ArialMT-70\" x=\"561.328125\"/>\n",
       "     <use xlink:href=\"#ArialMT-6c\" x=\"616.943359\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" x=\"639.160156\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" x=\"694.775391\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 197.010937 149.879219 \n",
       "L 268.889063 149.879219 \n",
       "Q 271.089063 149.879219 271.089063 147.679219 \n",
       "L 271.089063 117.659531 \n",
       "Q 271.089063 115.459531 268.889063 115.459531 \n",
       "L 197.010937 115.459531 \n",
       "Q 194.810937 115.459531 194.810937 117.659531 \n",
       "L 194.810937 147.679219 \n",
       "Q 194.810937 149.879219 197.010937 149.879219 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"PathCollection_3\">\n",
       "     <g>\n",
       "      <use xlink:href=\"#me584df1ed5\" x=\"210.210938\" y=\"124.845625\" style=\"fill: #4c72b0; stroke: #333333\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- Class 0 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(230.010938 127.733125) scale(0.11 -0.11)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-43\" d=\"M 3763 1606 \n",
       "L 4369 1453 \n",
       "Q 4178 706 3683 314 \n",
       "Q 3188 -78 2472 -78 \n",
       "Q 1731 -78 1267 223 \n",
       "Q 803 525 561 1097 \n",
       "Q 319 1669 319 2325 \n",
       "Q 319 3041 592 3573 \n",
       "Q 866 4106 1370 4382 \n",
       "Q 1875 4659 2481 4659 \n",
       "Q 3169 4659 3637 4309 \n",
       "Q 4106 3959 4291 3325 \n",
       "L 3694 3184 \n",
       "Q 3534 3684 3231 3912 \n",
       "Q 2928 4141 2469 4141 \n",
       "Q 1941 4141 1586 3887 \n",
       "Q 1231 3634 1087 3207 \n",
       "Q 944 2781 944 2328 \n",
       "Q 944 1744 1114 1308 \n",
       "Q 1284 872 1643 656 \n",
       "Q 2003 441 2422 441 \n",
       "Q 2931 441 3284 734 \n",
       "Q 3638 1028 3763 1606 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-43\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" x=\"72.216797\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" x=\"94.433594\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"150.048828\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"200.048828\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" x=\"250.048828\"/>\n",
       "      <use xlink:href=\"#ArialMT-30\" x=\"277.832031\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"PathCollection_4\">\n",
       "     <g>\n",
       "      <use xlink:href=\"#mde6b2d7519\" x=\"210.210938\" y=\"140.405469\" style=\"fill: #dd8452; stroke: #333333\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- Class 1 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(230.010938 143.292969) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-43\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" x=\"72.216797\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" x=\"94.433594\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"150.048828\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" x=\"200.048828\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" x=\"250.048828\"/>\n",
       "      <use xlink:href=\"#ArialMT-31\" x=\"277.832031\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p298a4fa963\">\n",
       "   <rect x=\"53.389062\" y=\"21.789375\" width=\"223.2\" height=\"221.76\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_samples(dataset.data, dataset.label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaVX9GEqiqm1"
   },
   "source": [
    "#### The data loader class\n",
    "\n",
    "The class `torch.utils.data.DataLoader` represents a Python iterable over a dataset with support for automatic batching, multi-process data loading and many more features. The data loader communicates with the dataset using the function `__getitem__`, and stacks its outputs as tensors over the first dimension to form a batch.\n",
    "In contrast to the dataset class, we usually don't have to define our own data loader class, but can just create an object of it with the dataset as input. Additionally, we can configure our data loader with the following input arguments (only a selection, see full list [here](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)):\n",
    "\n",
    "* `batch_size`: Number of samples to stack per batch\n",
    "* `shuffle`: If True, the data is returned in a random order. This is important during training for introducing stochasticity. \n",
    "* `num_workers`: Number of subprocesses to use for data loading. The default, 0, means that the data will be loaded in the main process which can slow down training for datasets where loading a data point takes a considerable amount of time (e.g. large images). More workers are recommended for those, but can cause issues on Windows computers. For tiny datasets as ours, 0 workers are usually faster.\n",
    "* `pin_memory`: If True, the data loader will copy Tensors into CUDA pinned memory before returning them. This can save some time for large data points on GPUs. Usually a good practice to use for a training set, but not necessarily for validation and test to save memory on the GPU.\n",
    "* `drop_last`: If True, the last batch is dropped in case it is smaller than the specified batch size. This occurs when the dataset size is not a multiple of the batch size. Only potentially helpful during training to keep a consistent batch size.\n",
    "\n",
    "Let's create a simple data loader below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1681656575570,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "Bls9PVIXiqcd",
    "outputId": "37769b53-2ca9-41ea-ce3a-66e225bc3671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inputs torch.Size([8, 2]) \n",
      " tensor([[ 1.0365,  1.0789],\n",
      "        [-0.1534,  0.9126],\n",
      "        [ 0.0645,  0.0353],\n",
      "        [-0.2095, -0.0954],\n",
      "        [ 1.1956,  1.1768],\n",
      "        [ 1.1498,  1.0044],\n",
      "        [ 1.1919, -0.1651],\n",
      "        [-0.0516, -0.0753]])\n",
      "Data labels torch.Size([8]) \n",
      " tensor([0, 1, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "# next(iter(...)) catches the first batch of the data loader\n",
    "# If shuffle is True, this will return a different batch every time we run this cell\n",
    "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
    "data_inputs, data_labels = next(iter(data_loader))\n",
    "\n",
    "# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the \n",
    "# dimensions of the data point returned from the dataset class\n",
    "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
    "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORKG-xxs2br1"
   },
   "source": [
    "### Optimization\n",
    "\n",
    "After defining the model and the dataset, it is time to prepare the optimization of the model. During training, we will perform the following steps:\n",
    "\n",
    "1. Get a batch from the data loader\n",
    "2. Obtain the predictions from the model for the batch\n",
    "3. Calculate the loss based on the difference between predictions and labels\n",
    "4. Backpropagation: calculate the gradients for every parameter with respect to the loss\n",
    "5. Update the parameters of the model in the direction of the gradients\n",
    "\n",
    "We have seen how we can do step 1, 2 and 4 in PyTorch. Now, we will look at step 3 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i38rtgeyi3xg"
   },
   "source": [
    "#### Loss modules\n",
    "\n",
    "We can calculate the loss for a batch by simply performing a few tensor operations as those are automatically added to the computation graph. For instance, for binary classification, we can use Binary Cross Entropy (BCE) which is defined as follows:\n",
    "\n",
    "$$\\mathcal{L}_{BCE} = -\\sum_i \\left[ y_i \\log x_i + (1 - y_i) \\log (1 - x_i) \\right]$$\n",
    "\n",
    "where $y$ are our labels, and $x$ our predictions, both in the range of $[0,1]$. However, PyTorch already provides a list of predefined loss functions which we can use (see [here](https://pytorch.org/docs/stable/nn.html#loss-functions) for a full list). For instance, for BCE, PyTorch has two modules: `nn.BCELoss()`, `nn.BCEWithLogitsLoss()`. While `nn.BCELoss` expects the inputs $x$ to be in the range $[0,1]$, i.e. the output of a sigmoid, `nn.BCEWithLogitsLoss` combines a sigmoid layer and the BCE loss in a single class. This version is numerically more stable than using a plain Sigmoid followed by a BCE loss because of the logarithms applied in the loss function. Hence, it is adviced to use loss functions applied on \"logits\" where possible (remember to not apply a sigmoid on the output of the model in this case!). For our model defined above, we therefore use the module `nn.BCEWithLogitsLoss`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "tjnSMotsi26w"
   },
   "outputs": [],
   "source": [
    "loss_module = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYixEUPsjCTP"
   },
   "source": [
    "#### Stochastic Gradient Descent\n",
    "\n",
    "For updating the parameters, PyTorch provides the package `torch.optim` that has most popular optimizers implemented. We will discuss the specific optimizers and their differences later in the course, but will for now use the simplest of them: `torch.optim.SGD`. Stochastic Gradient Descent updates parameters by multiplying the gradients with a small constant, called learning rate, and subtracting those from the parameters (hence minimizing the loss). Therefore, we slowly move towards the direction of minimizing the loss. A good default value of the learning rate for a small network as ours is 0.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "EEwNVYqk2gq8"
   },
   "outputs": [],
   "source": [
    "# Input to the optimizer are the parameters of the model: model.parameters()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TML9k2gAjLbr"
   },
   "source": [
    "The optimizer provides two useful functions: `optimizer.step()`, and `optimizer.zero_grad()`. The step function updates the parameters based on the gradients as explained above. The function `optimizer.zero_grad()` sets the gradients of all parameters to zero. While this function seems less relevant at first, it is a crucial pre-step before performing backpropagation. If we call the `backward` function on the loss while the parameter gradients are non-zero from the previous batch, the new gradients would actually be added to the previous ones instead of overwriting them. This is done because a parameter might occur multiple times in a computation graph, and we need to sum the gradients in this case instead of replacing them. Hence, remember to call `optimizer.zero_grad()` before calculating the gradients of a batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKKG5I4djT_V"
   },
   "source": [
    "### Training\n",
    "\n",
    "Finally, we are ready to train our model. As a first step, we create a slightly larger dataset and specify a data loader with a larger batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "9RTyu7bi2nO1"
   },
   "outputs": [],
   "source": [
    "train_dataset = XORDataset(size=2500)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxyoXnzujaVt"
   },
   "source": [
    "Now, we can write a small training function. Remember our five steps: load a batch, obtain the predictions, calculate the loss, backpropagate, and update. Additionally, we have to push all data and model parameters to the device of our choice (GPU if available). For the tiny neural network we have, communicating the data to the GPU actually takes much more time than we could save from running the operation on GPU. For large networks, the communication time is significantly smaller than the actual runtime making a GPU crucial in these cases. \n",
    "\n",
    "Here we introduce how to detect and set your device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681656938019,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "UQ3aViQC22lf",
    "outputId": "5ff7d2b2-cf34-4d04-be24-10cf76581a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the GPU available? False\n",
      "Device cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleClassifier(\n",
       "  (linear1): Linear(in_features=2, out_features=4, bias=True)\n",
       "  (act_fn): Tanh()\n",
       "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "# GPU operations have a separate seed we also want to set\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Push model to device. Has to be only done once\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTJ772q8kLiu"
   },
   "source": [
    "In addition, we set our model to training mode. This is done by calling `model.train()`. There exist certain modules that need to perform a different forward step during training than during testing (e.g. BatchNorm and Dropout), and we can switch between them using `model.train()` and `model.eval()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "bOKQyaET25Fl"
   },
   "outputs": [],
   "source": [
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
    "    # Set model to train mode\n",
    "    model.train() \n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            \n",
    "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "            \n",
    "            ## Step 2: Run the model on the input data\n",
    "            preds = model(data_inputs)\n",
    "            \n",
    "            ## Step 3: Calculate the loss\n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "            \n",
    "            ## Step 4: Perform backpropagation\n",
    "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
    "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "            optimizer.zero_grad() \n",
    "            # Perform backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            ## Step 5: Update the parameters\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ddf6e42613a74614846d5910fb3243e0",
      "fdccac1138624e959fbd7d6d51c46910",
      "8105b1e0017b4b93a30fe470fa2ef77e",
      "aae307dd6c334f5988b24a77b42b5afe",
      "c4cd3bd468a54053b7c57f90f283e756",
      "1071207b463849fdad228aa3b0b00dc5",
      "83e7d4c65825400a9d76aa7048e65d11",
      "68d58f40e7294c29a19529a5e7b740b6",
      "dfa17791aee0481b8efc0bf943ef44dd",
      "35972bfe66ed404aad062f1de15c1805",
      "4a4c2502e544491181ded290add3422f"
     ]
    },
    "executionInfo": {
     "elapsed": 3233,
     "status": "ok",
     "timestamp": 1681657003830,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "E2OI60l5kQ7h",
    "outputId": "7dc79c5a-033f-4798-a2b1-34d7e7567841"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4a58afda04497db8812503d3a3b62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(model, optimizer, train_data_loader, loss_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wY_2AxtakdGi"
   },
   "source": [
    "#### Saving a model\n",
    "\n",
    "After finish training a model, we save the model to disk so that we can load the same weights at a later time. For this, we extract the so-called `state_dict` from the model which contains all learnable parameters. For our simple model, the state dict contains the following entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1681657036375,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "JMV5ESlFkfKS",
    "outputId": "cb827b2e-fdee-435e-8234-efd2f540a81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear1.weight', tensor([[-0.2075, -0.4527],\n",
      "        [ 2.9394, -2.8646],\n",
      "        [ 0.1873, -0.2180],\n",
      "        [-3.1686,  3.3013]])), ('linear1.bias', tensor([-1.0736,  1.4272, -0.8316,  1.5918])), ('linear2.weight', tensor([[-1.6621, -4.5029, -0.9341, -4.5958]])), ('linear2.bias', tensor([2.0791]))])\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "print(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlUQQeVU8weO"
   },
   "source": [
    "To save the state dictionary, we can use `torch.save`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "ZhvuiZlM85n2"
   },
   "outputs": [],
   "source": [
    "# torch.save(object, filename). For the filename, any extension can be used\n",
    "torch.save(state_dict, \"our_model.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXVTuYVgky3H"
   },
   "source": [
    "To load a model from a state dict, we use the function `torch.load` to load the state dict from the disk, and the module function `load_state_dict` to overwrite our parameters with the new values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "EuzOxYyo89Q1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model\n",
      " OrderedDict([('linear1.weight', tensor([[-0.2075, -0.4527],\n",
      "        [ 2.9394, -2.8646],\n",
      "        [ 0.1873, -0.2180],\n",
      "        [-3.1686,  3.3013]])), ('linear1.bias', tensor([-1.0736,  1.4272, -0.8316,  1.5918])), ('linear2.weight', tensor([[-1.6621, -4.5029, -0.9341, -4.5958]])), ('linear2.bias', tensor([2.0791]))])\n",
      "\n",
      "Loaded model\n",
      " OrderedDict([('linear1.weight', tensor([[-0.2075, -0.4527],\n",
      "        [ 2.9394, -2.8646],\n",
      "        [ 0.1873, -0.2180],\n",
      "        [-3.1686,  3.3013]])), ('linear1.bias', tensor([-1.0736,  1.4272, -0.8316,  1.5918])), ('linear2.weight', tensor([[-1.6621, -4.5029, -0.9341, -4.5958]])), ('linear2.bias', tensor([2.0791]))])\n"
     ]
    }
   ],
   "source": [
    "# Load state dict from the disk (make sure it is the same name as above)\n",
    "state_dict = torch.load(\"our_model.tar\")\n",
    "\n",
    "# Create a new model and load the state\n",
    "new_model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "new_model.load_state_dict(state_dict)\n",
    "\n",
    "# Verify that the parameters are the same\n",
    "print(\"Original model\\n\", model.state_dict())\n",
    "print(\"\\nLoaded model\\n\", new_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQ241Ay-k4O3"
   },
   "source": [
    "A detailed tutorial on saving and loading models in PyTorch can be found [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_uTmxoz3MSF"
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "Once we have trained a model, it is time to evaluate it on a held-out test set. As our dataset consist of randomly generated data points, we need to first create a test set with a corresponding data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "zrsUH6Yw3PUl"
   },
   "outputs": [],
   "source": [
    "test_dataset = XORDataset(size=500)\n",
    "# drop_last -> Don't drop the last batch although it is smaller than 128\n",
    "test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkSplsc8yeUl"
   },
   "source": [
    "As metric, we will use accuracy which is calculated as follows:\n",
    "\n",
    "$$acc = \\frac{\\#\\text{correct predictions}}{\\#\\text{all predictions}} = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "where TP are the true positives, TN true negatives, FP false positives, and FN the fale negatives. \n",
    "\n",
    "When evaluating the model, we don't need to keep track of the computation graph as we don't intend to calculate the gradients. This reduces the required memory and speed up the model. In PyTorch, we can deactivate the computation graph using `with torch.no_grad(): ...`. Remember to additionally set the model to eval mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "ds1l3JKC67D2"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader):\n",
    "    model.eval() # Set model to eval mode\n",
    "    true_preds, num_preds = 0., 0.\n",
    "    \n",
    "    with torch.no_grad(): # Deactivate gradients for the following code\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            \n",
    "            # Determine prediction of model on dev set\n",
    "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
    "            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
    "            \n",
    "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
    "            true_preds += (pred_labels == data_labels).sum()\n",
    "            num_preds += data_labels.shape[0]\n",
    "            \n",
    "    acc = true_preds / num_preds\n",
    "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1681657223884,
     "user": {
      "displayName": "Dr CAO Yixin _",
      "userId": "02213333189428679281"
     },
     "user_tz": -480
    },
    "id": "s6WCZu5elM5E",
    "outputId": "b9099e62-a0c8-4e00-b922-c3912dd9697b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 100.00%\n"
     ]
    }
   ],
   "source": [
    "eval_model(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-IGgpd-lfNe"
   },
   "source": [
    "If we trained our model correctly, we should see a score close to 100% accuracy. However, this is only possible because of our simple task, and unfortunately, we usually don't get such high scores on test sets of more complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79NshWDX6_f1"
   },
   "source": [
    "## Additional features we didn't get to discuss yet\n",
    "\n",
    "Finally, you are all set to start with your own PyTorch project! In summary, we have looked at how we can build neural networks in PyTorch, and train and test them on data. However, there is still much more to PyTorch we haven't discussed yet. In the coming series of Jupyter notebooks, we will discover more and more functionalities of PyTorch, so that you also get familiar to PyTorch concepts beyond the basics. If you are already interested in learning more of PyTorch, we recommend the official [tutorial website](https://pytorch.org/tutorials/) that contains many tutorials on various topics. Especially logging with Tensorboard ([official tutorial here](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)) is a good practice."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1071207b463849fdad228aa3b0b00dc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35972bfe66ed404aad062f1de15c1805": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a4c2502e544491181ded290add3422f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68d58f40e7294c29a19529a5e7b740b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8105b1e0017b4b93a30fe470fa2ef77e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68d58f40e7294c29a19529a5e7b740b6",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dfa17791aee0481b8efc0bf943ef44dd",
      "value": 100
     }
    },
    "83e7d4c65825400a9d76aa7048e65d11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aae307dd6c334f5988b24a77b42b5afe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35972bfe66ed404aad062f1de15c1805",
      "placeholder": "​",
      "style": "IPY_MODEL_4a4c2502e544491181ded290add3422f",
      "value": " 100/100 [00:03&lt;00:00, 29.92it/s]"
     }
    },
    "c4cd3bd468a54053b7c57f90f283e756": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddf6e42613a74614846d5910fb3243e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fdccac1138624e959fbd7d6d51c46910",
       "IPY_MODEL_8105b1e0017b4b93a30fe470fa2ef77e",
       "IPY_MODEL_aae307dd6c334f5988b24a77b42b5afe"
      ],
      "layout": "IPY_MODEL_c4cd3bd468a54053b7c57f90f283e756"
     }
    },
    "dfa17791aee0481b8efc0bf943ef44dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fdccac1138624e959fbd7d6d51c46910": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1071207b463849fdad228aa3b0b00dc5",
      "placeholder": "​",
      "style": "IPY_MODEL_83e7d4c65825400a9d76aa7048e65d11",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
